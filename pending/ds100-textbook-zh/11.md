# 梯度下降与数值优化

> 原文：[https://www.bookbookmark.ds100.org/ch/11/gradient_descence.html](https://www.bookbookmark.ds100.org/ch/11/gradient_descence.html)

```
# HIDDEN
# Clear previously defined variables
%reset -f

# Set directory for data loading to work properly
import os
os.chdir(os.path.expanduser('~/notebooks/11'))

```

为了使用数据集进行估计和预测，我们需要精确定义我们的模型并选择一个损失函数。例如，在 Tip Percentage 数据集中，我们的模型假设存在一个单独的 Tip 百分比，该百分比不会随表而变化。然后，我们决定使用均方误差损失函数，并找到最小化损失函数的模型。

我们还发现有一些简单的表达式可以最小化 MSE 和平均绝对误差损失函数：平均值和中位数。然而，随着我们的模型和损失函数变得更加复杂，我们将无法再为最小化损失的模型找到有用的代数表达式。例如，Huber 损耗具有有用的特性，但很难用手加以区分。

我们可以用计算机用梯度下降法来解决这个问题，这是一种最小化损失函数的计算方法。